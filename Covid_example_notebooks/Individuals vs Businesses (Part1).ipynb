{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1619672149900,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "3rOrW14BarN0",
    "outputId": "dc4b4144-4280-419d-fb1c-09932b130baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ms731/Documents/Physics/PhD/NLP/Analyzing-Twitter-Trends-On-COVID-19-Vaccinations/Codes Used/Data_Cleaning\n"
     ]
    }
   ],
   "source": [
    "%cd 'Data_Cleaning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1619672150665,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "9iw_t6OLawex",
    "outputId": "0cf95db0-3cf3-4ee3-b437-82d23f0664df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eighth Extract.csv     Second Extract.csv     Tweets_Feb.csv\r\n",
      "Fifth Extract.csv      Seventh Extract.csv    Tweets_Mar_Cleaned.csv\r\n",
      "First Extract.csv      Sixth Extract.csv\r\n",
      "Fourth Extract.csv     Third Extract.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1619672150666,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "fKL7ooRraxgq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 24284,
     "status": "ok",
     "timestamp": 1619672173820,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "wOeyDUzDaz6l"
   },
   "outputs": [],
   "source": [
    "Tweets_Jan_Cleaned = pd.read_csv('Tweets_Feb_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 24459,
     "status": "ok",
     "timestamp": 1619672173998,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "sK-ii3ifbdRs"
   },
   "outputs": [],
   "source": [
    "Tweets_Jan_Cleaned = Tweets_Jan_Cleaned.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25174,
     "status": "ok",
     "timestamp": 1619672174718,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "S--zywGJbNwN",
    "outputId": "4ee67e30-0217-4b35-dfaa-09789d3b2bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7839 entries, 0 to 7838\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0.1     7839 non-null   int64 \n",
      " 1   Datetime         7839 non-null   object\n",
      " 2   Tweet Id         7839 non-null   int64 \n",
      " 3   Text             7839 non-null   object\n",
      " 4   Username         7839 non-null   object\n",
      " 5   Like Count       7839 non-null   int64 \n",
      " 6   Display Name     7839 non-null   object\n",
      " 7   Language         7839 non-null   object\n",
      " 8   Text_punc        7839 non-null   object\n",
      " 9   Text_stop        7839 non-null   object\n",
      " 10  Text_tokenized   7839 non-null   object\n",
      " 11  Text_lemmatized  7839 non-null   object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 735.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Tweets_Jan_Cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 45966,
     "status": "ok",
     "timestamp": 1619672195515,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "iJcdsRkPfPZI"
   },
   "outputs": [],
   "source": [
    "Tweets_Feb_Cleaned = pd.read_csv('Tweets_Feb_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 46240,
     "status": "ok",
     "timestamp": 1619672195792,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "S43dgHVNfwWh"
   },
   "outputs": [],
   "source": [
    "Tweets_Feb_Cleaned = Tweets_Feb_Cleaned.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46841,
     "status": "ok",
     "timestamp": 1619672196398,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "Ypaj4TZrfri7",
    "outputId": "99f57e4f-09af-4acc-cffa-b0e3631ac4d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7839 entries, 0 to 7838\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0.1     7839 non-null   int64 \n",
      " 1   Datetime         7839 non-null   object\n",
      " 2   Tweet Id         7839 non-null   int64 \n",
      " 3   Text             7839 non-null   object\n",
      " 4   Username         7839 non-null   object\n",
      " 5   Like Count       7839 non-null   int64 \n",
      " 6   Display Name     7839 non-null   object\n",
      " 7   Language         7839 non-null   object\n",
      " 8   Text_punc        7839 non-null   object\n",
      " 9   Text_stop        7839 non-null   object\n",
      " 10  Text_tokenized   7839 non-null   object\n",
      " 11  Text_lemmatized  7839 non-null   object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 735.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Tweets_Feb_Cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 54156,
     "status": "ok",
     "timestamp": 1619672203717,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "pg9m6uMJfjmS"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tweets_Mar_Cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1594294417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTweets_Mar_Cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tweets_Mar_Cleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/twitter-covid-test/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tweets_Mar_Cleaned.csv'"
     ]
    }
   ],
   "source": [
    "Tweets_Mar_Cleaned = pd.read_csv('Tweets_Mar_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 54155,
     "status": "ok",
     "timestamp": 1619672203719,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "JMjnK8nkf9ef"
   },
   "outputs": [],
   "source": [
    "Tweets_Mar_Cleaned = Tweets_Mar_Cleaned.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54528,
     "status": "ok",
     "timestamp": 1619672204097,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "xE9FVAbhgArO",
    "outputId": "6de8a5b1-9c0a-4100-c7bb-4e133c88c02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   Datetime         1048575 non-null  object \n",
      " 1   Week             1048575 non-null  int64  \n",
      " 2   Tweet Id         1048575 non-null  float64\n",
      " 3   Username         1048572 non-null  object \n",
      " 4   Like Count       1048575 non-null  int64  \n",
      " 5   Display Name     1048546 non-null  object \n",
      " 6   Text_lemmatized  1048575 non-null  object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 56.0+ MB\n"
     ]
    }
   ],
   "source": [
    "Tweets_Mar_Cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54523,
     "status": "ok",
     "timestamp": 1619672204097,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "d8M3_gbshsZ2",
    "outputId": "dab3b7d7-2419-46a8-fc51-64a36916c7a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'Week', 'Tweet Id', 'Username', 'Like Count',\n",
       "       'Display Name', 'Text_lemmatized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_Mar_Cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 55195,
     "status": "ok",
     "timestamp": 1619672204774,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "4rHRrPWqbp5P"
   },
   "outputs": [],
   "source": [
    "#Tweets = pd.concat([Tweets_Jan_Cleaned[['Datetime', 'Week', 'Tweet Id', 'Username', 'Like Count', 'Display Name', 'Text_lemmatized']],Tweets_Feb_Cleaned[['Datetime', 'Week', 'Tweet Id', 'Username', 'Like Count','Display Name', 'Text_lemmatized']],Tweets_Mar_Cleaned[['Datetime', 'Week', 'Tweet Id', 'Username', 'Like Count','Display Name', 'Text_lemmatized']]])\n",
    "Tweets = Tweets_Feb_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55839,
     "status": "ok",
     "timestamp": 1619672205422,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "Jw5gIT8GiM3z",
    "outputId": "efa50847-4994-42ff-9dd0-48b135b07f74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7839, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56013,
     "status": "ok",
     "timestamp": 1619672205602,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "BwmWNMHyJfEo",
    "outputId": "3e9be7f5-1e30-4c1c-da9d-dd002b50ff53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6777"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tweets['Username'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 56010,
     "status": "ok",
     "timestamp": 1619672205604,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "6aZ9Ewv-iPr3"
   },
   "outputs": [],
   "source": [
    "Tweets.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 56311,
     "status": "ok",
     "timestamp": 1619672205907,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "zzeBtbvdix0X"
   },
   "outputs": [],
   "source": [
    "#Tweets = Tweets.sort_values('Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 56473,
     "status": "ok",
     "timestamp": 1619672206073,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "NURAVwsi__QH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tweets_Mar_Cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3582064899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTweets_Jan_Cleaned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTweets_Feb_Cleaned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTweets_Mar_Cleaned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Tweets_Mar_Cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "del([Tweets_Jan_Cleaned,Tweets_Feb_Cleaned,Tweets_Mar_Cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 80157,
     "status": "ok",
     "timestamp": 1619672229760,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "tp0fvbTmzjwF"
   },
   "outputs": [],
   "source": [
    "Tweets['.com']=Tweets['Display Name'].str.lower().str.contains(str.lower('.com'))\n",
    "Tweets['.net']=Tweets['Display Name'].str.lower().str.contains(str.lower('.net'))\n",
    "Tweets['24/7']=Tweets['Display Name'].str.lower().str.contains(str.lower('24/7'))\n",
    "Tweets['ABC']=Tweets['Display Name'].str.lower().str.contains(str.lower('ABC'))\n",
    "Tweets['ABS']=Tweets['Display Name'].str.lower().str.contains(str.lower('ABS'))\n",
    "Tweets['Affair']=Tweets['Display Name'].str.lower().str.contains(str.lower('Affair'))\n",
    "Tweets['Africa']=Tweets['Display Name'].str.lower().str.contains(str.lower('Africa'))\n",
    "Tweets['agency']=Tweets['Display Name'].str.lower().str.contains(str.lower('agency'))\n",
    "Tweets['Jazeera']=Tweets['Display Name'].str.lower().str.contains(str.lower('Jazeera'))\n",
    "Tweets['alert']=Tweets['Display Name'].str.lower().str.contains(str.lower('alert'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 103071,
     "status": "ok",
     "timestamp": 1619672252678,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "ovyNmJHIzj3x"
   },
   "outputs": [],
   "source": [
    "Tweets['America']=Tweets['Display Name'].str.lower().str.contains(str.lower('America'))\n",
    "Tweets['Asia']=Tweets['Display Name'].str.lower().str.contains(str.lower('Asia'))\n",
    "Tweets['Association']=Tweets['Display Name'].str.lower().str.contains(str.lower('Association'))\n",
    "Tweets['AstraZeneca']=Tweets['Display Name'].str.lower().str.contains(str.lower('AstraZeneca'))\n",
    "Tweets['Australia']=Tweets['Display Name'].str.lower().str.contains(str.lower('Australia'))\n",
    "Tweets['BBC']=Tweets['Display Name'].str.lower().str.contains(str.lower('BBC'))\n",
    "Tweets['BioNTech']=Tweets['Display Name'].str.lower().str.contains(str.lower('BioNTech'))\n",
    "Tweets['Biotech']=Tweets['Display Name'].str.lower().str.contains(str.lower('Biotech'))\n",
    "Tweets['Bloomberg']=Tweets['Display Name'].str.lower().str.contains(str.lower('Bloomberg'))\n",
    "Tweets['breaking']=Tweets['Display Name'].str.lower().str.contains(str.lower('breaking'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 125605,
     "status": "ok",
     "timestamp": 1619672275215,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "j8Pz4v_SzkBp"
   },
   "outputs": [],
   "source": [
    "Tweets['Brief']=Tweets['Display Name'].str.lower().str.contains(str.lower('Brief'))\n",
    "Tweets['Briefly']=Tweets['Display Name'].str.lower().str.contains(str.lower('Briefly'))\n",
    "Tweets['Bulletin']=Tweets['Display Name'].str.lower().str.contains(str.lower('Bulletin'))\n",
    "Tweets['Business']=Tweets['Display Name'].str.lower().str.contains(str.lower('Business'))\n",
    "Tweets['Buzz']=Tweets['Display Name'].str.lower().str.contains(str.lower('Buzz'))\n",
    "Tweets['Canada']=Tweets['Display Name'].str.lower().str.contains(str.lower('Canada'))\n",
    "Tweets['CBS']=Tweets['Display Name'].str.lower().str.contains(str.lower('CBS'))\n",
    "Tweets['CDC']=Tweets['Display Name'].str.lower().str.contains(str.lower('CDC'))\n",
    "Tweets['Central']=Tweets['Display Name'].str.lower().str.contains(str.lower('Central'))\n",
    "Tweets['channel']=Tweets['Display Name'].str.lower().str.contains(str.lower('channel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 148428,
     "status": "ok",
     "timestamp": 1619672298041,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "v7EIabJ-zkJt"
   },
   "outputs": [],
   "source": [
    "Tweets['China']=Tweets['Display Name'].str.lower().str.contains(str.lower('China'))\n",
    "Tweets['Chronicle']=Tweets['Display Name'].str.lower().str.contains(str.lower('Chronicle'))\n",
    "Tweets['Circuit']=Tweets['Display Name'].str.lower().str.contains(str.lower('Circuit'))\n",
    "Tweets['Citizen']=Tweets['Display Name'].str.lower().str.contains(str.lower('Citizen'))\n",
    "Tweets['city']=Tweets['Display Name'].str.lower().str.contains(str.lower('city'))\n",
    "Tweets['CNA']=Tweets['Display Name'].str.lower().str.contains(str.lower('CNA'))\n",
    "Tweets['CNN']=Tweets['Display Name'].str.lower().str.contains(str.lower('CNN'))\n",
    "Tweets['Commercial']=Tweets['Display Name'].str.lower().str.contains(str.lower('Commercial'))\n",
    "Tweets['consulting']=Tweets['Display Name'].str.lower().str.contains(str.lower('consulting'))\n",
    "Tweets['CoronaVac']=Tweets['Display Name'].str.lower().str.contains(str.lower('CoronaVac'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 171028,
     "status": "ok",
     "timestamp": 1619672320644,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "rYvsNL-9zkSl"
   },
   "outputs": [],
   "source": [
    "Tweets['Council']=Tweets['Display Name'].str.lower().str.contains(str.lower('Council'))\n",
    "Tweets['county']=Tweets['Display Name'].str.lower().str.contains(str.lower('county'))\n",
    "Tweets['Covaxin']=Tweets['Display Name'].str.lower().str.contains(str.lower('Covaxin'))\n",
    "Tweets['Covid']=Tweets['Display Name'].str.lower().str.contains(str.lower('Covid'))\n",
    "Tweets['Covid-19']=Tweets['Display Name'].str.lower().str.contains(str.lower('Covid-19'))\n",
    "Tweets['CoviShield']=Tweets['Display Name'].str.lower().str.contains(str.lower('CoviShield'))\n",
    "Tweets['Current']=Tweets['Display Name'].str.lower().str.contains(str.lower('Current'))\n",
    "Tweets['CVS']=Tweets['Display Name'].str.lower().str.contains(str.lower('CVS'))\n",
    "Tweets['daily']=Tweets['Display Name'].str.lower().str.contains(str.lower('daily'))\n",
    "Tweets['Desk']=Tweets['Display Name'].str.lower().str.contains(str.lower('Desk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 193855,
     "status": "ok",
     "timestamp": 1619672343474,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "4DAPaIZzzkZ5"
   },
   "outputs": [],
   "source": [
    "Tweets['Dialogue']=Tweets['Display Name'].str.lower().str.contains(str.lower('Dialogue'))\n",
    "Tweets['Digital']=Tweets['Display Name'].str.lower().str.contains(str.lower('Digital'))\n",
    "Tweets['Eastern']=Tweets['Display Name'].str.lower().str.contains(str.lower('Eastern'))\n",
    "Tweets['Economic']=Tweets['Display Name'].str.lower().str.contains(str.lower('Economic'))\n",
    "Tweets['Empire']=Tweets['Display Name'].str.lower().str.contains(str.lower('Empire'))\n",
    "Tweets['EpiVacCorona']=Tweets['Display Name'].str.lower().str.contains(str.lower('EpiVacCorona'))\n",
    "Tweets['Europe']=Tweets['Display Name'].str.lower().str.contains(str.lower('Europe'))\n",
    "Tweets['Express']=Tweets['Display Name'].str.lower().str.contains(str.lower('Express'))\n",
    "Tweets['Federation']=Tweets['Display Name'].str.lower().str.contains(str.lower('Federation'))\n",
    "Tweets['feeds']=Tweets['Display Name'].str.lower().str.contains(str.lower('feeds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 216713,
     "status": "ok",
     "timestamp": 1619672366335,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "q-Fzi7J45D4I"
   },
   "outputs": [],
   "source": [
    "Tweets['Finder']=Tweets['Display Name'].str.lower().str.contains(str.lower('Finder'))\n",
    "Tweets['First']=Tweets['Display Name'].str.lower().str.contains(str.lower('First'))\n",
    "Tweets['Forbes']=Tweets['Display Name'].str.lower().str.contains(str.lower('Forbes'))\n",
    "Tweets['Fox']=Tweets['Display Name'].str.lower().str.contains(str.lower('Fox'))\n",
    "Tweets['General']=Tweets['Display Name'].str.lower().str.contains(str.lower('General'))\n",
    "Tweets['global']=Tweets['Display Name'].str.lower().str.contains(str.lower('global'))\n",
    "Tweets['gov']=Tweets['Display Name'].str.lower().str.contains(str.lower('gov'))\n",
    "Tweets['group']=Tweets['Display Name'].str.lower().str.contains(str.lower('group'))\n",
    "Tweets['Guardian']=Tweets['Display Name'].str.lower().str.contains(str.lower('Guardian'))\n",
    "Tweets['headline']=Tweets['Display Name'].str.lower().str.contains(str.lower('headline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 242056,
     "status": "ok",
     "timestamp": 1619672391681,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "rQ0WQN6J5D7C"
   },
   "outputs": [],
   "source": [
    "Tweets['Headlines']=Tweets['Display Name'].str.lower().str.contains(str.lower('Headlines'))\n",
    "Tweets['health']=Tweets['Display Name'].str.lower().str.contains(str.lower('health'))\n",
    "Tweets['hospital']=Tweets['Display Name'].str.lower().str.contains(str.lower('hospital'))\n",
    "Tweets['Hour']=Tweets['Display Name'].str.lower().str.contains(str.lower('Hour'))\n",
    "Tweets['Hub']=Tweets['Display Name'].str.lower().str.contains(str.lower('Hub'))\n",
    "Tweets['India']=Tweets['Display Name'].str.lower().str.contains(str.lower('India'))\n",
    "Tweets['Insider']=Tweets['Display Name'].str.lower().str.contains(str.lower('Insider'))\n",
    "Tweets['Issues']=Tweets['Display Name'].str.lower().str.contains(str.lower('Issues'))\n",
    "Tweets['Janssen']=Tweets['Display Name'].str.lower().str.contains(str.lower('Janssen'))\n",
    "Tweets['Johnson & Johnson']=Tweets['Display Name'].str.lower().str.contains(str.lower('Johnson & Johnson'))\n",
    "Tweets['J&J']=Tweets['Display Name'].str.lower().str.contains(str.lower('J&J'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 264929,
     "status": "ok",
     "timestamp": 1619672414557,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "B4tq6nFS5D9o"
   },
   "outputs": [],
   "source": [
    "Tweets['Journal']=Tweets['Display Name'].str.lower().str.contains(str.lower('Journal'))\n",
    "Tweets['Journalists']=Tweets['Display Name'].str.lower().str.contains(str.lower('Journalists'))\n",
    "Tweets['Kroger']=Tweets['Display Name'].str.lower().str.contains(str.lower('Kroger'))\n",
    "Tweets['Latest']=Tweets['Display Name'].str.lower().str.contains(str.lower('Latest'))\n",
    "Tweets['Live']=Tweets['Display Name'].str.lower().str.contains(str.lower('Live'))\n",
    "Tweets['LLC']=Tweets['Display Name'].str.lower().str.contains(str.lower('LLC'))\n",
    "Tweets['local']=Tweets['Display Name'].str.lower().str.contains(str.lower('local'))\n",
    "Tweets['mail']=Tweets['Display Name'].str.lower().str.contains(str.lower('mail'))\n",
    "Tweets['Market']=Tweets['Display Name'].str.lower().str.contains(str.lower('Market'))\n",
    "Tweets['mass']=Tweets['Display Name'].str.lower().str.contains(str.lower('mass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 291632,
     "status": "ok",
     "timestamp": 1619672441263,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "AWcwF96L5EAD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3731971694.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['nation']=Tweets['Display Name'].str.lower().str.contains(str.lower('nation'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3731971694.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['National']=Tweets['Display Name'].str.lower().str.contains(str.lower('National'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3731971694.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['NBC']=Tweets['Display Name'].str.lower().str.contains(str.lower('NBC'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['media']=Tweets['Display Name'].str.lower().str.contains(str.lower('media'))\n",
    "Tweets['Medical']=Tweets['Display Name'].str.lower().str.contains(str.lower('Medical'))\n",
    "Tweets['Medium']=Tweets['Display Name'].str.lower().str.contains(str.lower('Medium'))\n",
    "Tweets['Messenger']=Tweets['Display Name'].str.lower().str.contains(str.lower('Messenger'))\n",
    "Tweets['Moderna']=Tweets['Display Name'].str.lower().str.contains(str.lower('Moderna'))\n",
    "Tweets['Month']=Tweets['Display Name'].str.lower().str.contains(str.lower('Month'))\n",
    "Tweets['Morning']=Tweets['Display Name'].str.lower().str.contains(str.lower('Morning'))\n",
    "Tweets['nation']=Tweets['Display Name'].str.lower().str.contains(str.lower('nation'))\n",
    "Tweets['National']=Tweets['Display Name'].str.lower().str.contains(str.lower('National'))\n",
    "Tweets['NBC']=Tweets['Display Name'].str.lower().str.contains(str.lower('NBC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 314834,
     "status": "ok",
     "timestamp": 1619672464468,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "P_O0Lpxm5ECs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['network']=Tweets['Display Name'].str.lower().str.contains(str.lower('network'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['New York']=Tweets['Display Name'].str.lower().str.contains(str.lower('New York'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['news']=Tweets['Display Name'].str.lower().str.contains(str.lower('news'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Newspaper']=Tweets['Display Name'].str.lower().str.contains(str.lower('Newspaper'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Novavax']=Tweets['Display Name'].str.lower().str.contains(str.lower('Novavax'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Now']=Tweets['Display Name'].str.lower().str.contains(str.lower('Now'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['online']=Tweets['Display Name'].str.lower().str.contains(str.lower('online'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Org']=Tweets['Display Name'].str.lower().str.contains(str.lower('Org'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['organization']=Tweets['Display Name'].str.lower().str.contains(str.lower('organization'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/300727931.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Pandemic']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pandemic'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['network']=Tweets['Display Name'].str.lower().str.contains(str.lower('network'))\n",
    "Tweets['New York']=Tweets['Display Name'].str.lower().str.contains(str.lower('New York'))\n",
    "Tweets['news']=Tweets['Display Name'].str.lower().str.contains(str.lower('news'))\n",
    "Tweets['Newspaper']=Tweets['Display Name'].str.lower().str.contains(str.lower('Newspaper'))\n",
    "Tweets['Novavax']=Tweets['Display Name'].str.lower().str.contains(str.lower('Novavax'))\n",
    "Tweets['Now']=Tweets['Display Name'].str.lower().str.contains(str.lower('Now'))\n",
    "Tweets['online']=Tweets['Display Name'].str.lower().str.contains(str.lower('online'))\n",
    "Tweets['Org']=Tweets['Display Name'].str.lower().str.contains(str.lower('Org'))\n",
    "Tweets['organization']=Tweets['Display Name'].str.lower().str.contains(str.lower('organization'))\n",
    "Tweets['Pandemic']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pandemic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 338101,
     "status": "ok",
     "timestamp": 1619672487740,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "9EgtHmir5EFA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Pfizer']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pfizer'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Pharmacy']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pharmacy'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Philippines']=Tweets['Display Name'].str.lower().str.contains(str.lower('Philippines'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Podcast']=Tweets['Display Name'].str.lower().str.contains(str.lower('Podcast'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Policy']=Tweets['Display Name'].str.lower().str.contains(str.lower('Policy'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Political']=Tweets['Display Name'].str.lower().str.contains(str.lower('Political'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Popular']=Tweets['Display Name'].str.lower().str.contains(str.lower('Popular'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Post']=Tweets['Display Name'].str.lower().str.contains(str.lower('Post'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['press']=Tweets['Display Name'].str.lower().str.contains(str.lower('press'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/274035580.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Progress']=Tweets['Display Name'].str.lower().str.contains(str.lower('Progress'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['Pfizer']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pfizer'))\n",
    "Tweets['Pharmacy']=Tweets['Display Name'].str.lower().str.contains(str.lower('Pharmacy'))\n",
    "Tweets['Philippines']=Tweets['Display Name'].str.lower().str.contains(str.lower('Philippines'))\n",
    "Tweets['Podcast']=Tweets['Display Name'].str.lower().str.contains(str.lower('Podcast'))\n",
    "Tweets['Policy']=Tweets['Display Name'].str.lower().str.contains(str.lower('Policy'))\n",
    "Tweets['Political']=Tweets['Display Name'].str.lower().str.contains(str.lower('Political'))\n",
    "Tweets['Popular']=Tweets['Display Name'].str.lower().str.contains(str.lower('Popular'))\n",
    "Tweets['Post']=Tweets['Display Name'].str.lower().str.contains(str.lower('Post'))\n",
    "Tweets['press']=Tweets['Display Name'].str.lower().str.contains(str.lower('press'))\n",
    "Tweets['Progress']=Tweets['Display Name'].str.lower().str.contains(str.lower('Progress'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 361314,
     "status": "ok",
     "timestamp": 1619672510956,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "CxKlaSpE5EHq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Project']=Tweets['Display Name'].str.lower().str.contains(str.lower('Project'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Public']=Tweets['Display Name'].str.lower().str.contains(str.lower('Public'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Radio']=Tweets['Display Name'].str.lower().str.contains(str.lower('Radio'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Reporter']=Tweets['Display Name'].str.lower().str.contains(str.lower('Reporter'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Republic']=Tweets['Display Name'].str.lower().str.contains(str.lower('Republic'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Reuters']=Tweets['Display Name'].str.lower().str.contains(str.lower('Reuters'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Science']=Tweets['Display Name'].str.lower().str.contains(str.lower('Science'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Sinopharm']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sinopharm'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Sinovac']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sinovac'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/4226246921.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Sky']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sky'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['Project']=Tweets['Display Name'].str.lower().str.contains(str.lower('Project'))\n",
    "Tweets['Public']=Tweets['Display Name'].str.lower().str.contains(str.lower('Public'))\n",
    "Tweets['Radio']=Tweets['Display Name'].str.lower().str.contains(str.lower('Radio'))\n",
    "Tweets['Reporter']=Tweets['Display Name'].str.lower().str.contains(str.lower('Reporter'))\n",
    "Tweets['Republic']=Tweets['Display Name'].str.lower().str.contains(str.lower('Republic'))\n",
    "Tweets['Reuters']=Tweets['Display Name'].str.lower().str.contains(str.lower('Reuters'))\n",
    "Tweets['Science']=Tweets['Display Name'].str.lower().str.contains(str.lower('Science'))\n",
    "Tweets['Sinopharm']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sinopharm'))\n",
    "Tweets['Sinovac']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sinovac'))\n",
    "Tweets['Sky']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 386574,
     "status": "ok",
     "timestamp": 1619672536219,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "cepQEr-15ELB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Society']=Tweets['Display Name'].str.lower().str.contains(str.lower('Society'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Sputnik']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sputnik'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Square']=Tweets['Display Name'].str.lower().str.contains(str.lower('Square'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['state']=Tweets['Display Name'].str.lower().str.contains(str.lower('state'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Stigma']=Tweets['Display Name'].str.lower().str.contains(str.lower('Stigma'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Street']=Tweets['Display Name'].str.lower().str.contains(str.lower('Street'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Studio']=Tweets['Display Name'].str.lower().str.contains(str.lower('Studio'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Talk']=Tweets['Display Name'].str.lower().str.contains(str.lower('Talk'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['team']=Tweets['Display Name'].str.lower().str.contains(str.lower('team'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Tech']=Tweets['Display Name'].str.lower().str.contains(str.lower('Tech'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1998454169.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Technology']=Tweets['Display Name'].str.lower().str.contains(str.lower('Technology'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['Society']=Tweets['Display Name'].str.lower().str.contains(str.lower('Society'))\n",
    "Tweets['Sputnik']=Tweets['Display Name'].str.lower().str.contains(str.lower('Sputnik'))\n",
    "Tweets['Square']=Tweets['Display Name'].str.lower().str.contains(str.lower('Square'))\n",
    "Tweets['state']=Tweets['Display Name'].str.lower().str.contains(str.lower('state'))\n",
    "Tweets['Stigma']=Tweets['Display Name'].str.lower().str.contains(str.lower('Stigma'))\n",
    "Tweets['Street']=Tweets['Display Name'].str.lower().str.contains(str.lower('Street'))\n",
    "Tweets['Studio']=Tweets['Display Name'].str.lower().str.contains(str.lower('Studio'))\n",
    "Tweets['Talk']=Tweets['Display Name'].str.lower().str.contains(str.lower('Talk'))\n",
    "Tweets['team']=Tweets['Display Name'].str.lower().str.contains(str.lower('team'))\n",
    "Tweets['Tech']=Tweets['Display Name'].str.lower().str.contains(str.lower('Tech'))\n",
    "Tweets['Technology']=Tweets['Display Name'].str.lower().str.contains(str.lower('Technology'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 409647,
     "status": "ok",
     "timestamp": 1619672559295,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "EzU0BgjFzkiE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Telegram']=Tweets['Display Name'].str.lower().str.contains(str.lower('Telegram'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Telegraph']=Tweets['Display Name'].str.lower().str.contains(str.lower('Telegraph'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['times']=Tweets['Display Name'].str.lower().str.contains(str.lower('times'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['today']=Tweets['Display Name'].str.lower().str.contains(str.lower('today'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['TOI']=Tweets['Display Name'].str.lower().str.contains(str.lower('TOI'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Top']=Tweets['Display Name'].str.lower().str.contains(str.lower('Top'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Top10']=Tweets['Display Name'].str.lower().str.contains(str.lower('Top10'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['trend']=Tweets['Display Name'].str.lower().str.contains(str.lower('trend'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Tribune']=Tweets['Display Name'].str.lower().str.contains(str.lower('Tribune'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/2582195083.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['TV']=Tweets['Display Name'].str.lower().str.contains(str.lower('TV'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['Telegram']=Tweets['Display Name'].str.lower().str.contains(str.lower('Telegram'))\n",
    "Tweets['Telegraph']=Tweets['Display Name'].str.lower().str.contains(str.lower('Telegraph'))\n",
    "Tweets['times']=Tweets['Display Name'].str.lower().str.contains(str.lower('times'))\n",
    "Tweets['today']=Tweets['Display Name'].str.lower().str.contains(str.lower('today'))\n",
    "Tweets['TOI']=Tweets['Display Name'].str.lower().str.contains(str.lower('TOI'))\n",
    "Tweets['Top']=Tweets['Display Name'].str.lower().str.contains(str.lower('Top'))\n",
    "Tweets['Top10']=Tweets['Display Name'].str.lower().str.contains(str.lower('Top10'))\n",
    "Tweets['trend']=Tweets['Display Name'].str.lower().str.contains(str.lower('trend'))\n",
    "Tweets['Tribune']=Tweets['Display Name'].str.lower().str.contains(str.lower('Tribune'))\n",
    "Tweets['TV']=Tweets['Display Name'].str.lower().str.contains(str.lower('TV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 432469,
     "status": "ok",
     "timestamp": 1619672582119,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "AA9ZnTrpzkp-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Union']=Tweets['Display Name'].str.lower().str.contains(str.lower('Union'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['update']=Tweets['Display Name'].str.lower().str.contains(str.lower('update'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['USA']=Tweets['Display Name'].str.lower().str.contains(str.lower('USA'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['vaccine']=Tweets['Display Name'].str.lower().str.contains(str.lower('vaccine'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Viral']=Tweets['Display Name'].str.lower().str.contains(str.lower('Viral'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Voice']=Tweets['Display Name'].str.lower().str.contains(str.lower('Voice'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Walgreens']=Tweets['Display Name'].str.lower().str.contains(str.lower('Walgreens'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Watch']=Tweets['Display Name'].str.lower().str.contains(str.lower('Watch'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Week1']=Tweets['Display Name'].str.lower().str.contains(str.lower('Week'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/1696686269.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Western']=Tweets['Display Name'].str.lower().str.contains(str.lower('Western'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['Union']=Tweets['Display Name'].str.lower().str.contains(str.lower('Union'))\n",
    "Tweets['update']=Tweets['Display Name'].str.lower().str.contains(str.lower('update'))\n",
    "Tweets['USA']=Tweets['Display Name'].str.lower().str.contains(str.lower('USA'))\n",
    "Tweets['vaccine']=Tweets['Display Name'].str.lower().str.contains(str.lower('vaccine'))\n",
    "Tweets['Viral']=Tweets['Display Name'].str.lower().str.contains(str.lower('Viral'))\n",
    "Tweets['Voice']=Tweets['Display Name'].str.lower().str.contains(str.lower('Voice'))\n",
    "Tweets['Walgreens']=Tweets['Display Name'].str.lower().str.contains(str.lower('Walgreens'))\n",
    "Tweets['Watch']=Tweets['Display Name'].str.lower().str.contains(str.lower('Watch'))\n",
    "Tweets['Week1']=Tweets['Display Name'].str.lower().str.contains(str.lower('Week'))\n",
    "Tweets['Western']=Tweets['Display Name'].str.lower().str.contains(str.lower('Western'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 448001,
     "status": "ok",
     "timestamp": 1619672597655,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "1dnaAxKyzkzQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['WHO']=Tweets['Display Name'].str.lower().str.contains(str.lower('WHO'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Wire']=Tweets['Display Name'].str.lower().str.contains(str.lower('Wire'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['world']=Tweets['Display Name'].str.lower().str.contains(str.lower('world'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Wuhan']=Tweets['Display Name'].str.lower().str.contains(str.lower('Wuhan'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Yahoo']=Tweets['Display Name'].str.lower().str.contains(str.lower('Yahoo'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Zone']=Tweets['Display Name'].str.lower().str.contains(str.lower('Zone'))\n",
      "/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_14740/3897348212.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Tweets['Zydus']=Tweets['Display Name'].str.lower().str.contains(str.lower('Zydus'))\n"
     ]
    }
   ],
   "source": [
    "Tweets['WHO']=Tweets['Display Name'].str.lower().str.contains(str.lower('WHO'))\n",
    "Tweets['Wire']=Tweets['Display Name'].str.lower().str.contains(str.lower('Wire'))\n",
    "Tweets['world']=Tweets['Display Name'].str.lower().str.contains(str.lower('world'))\n",
    "Tweets['Wuhan']=Tweets['Display Name'].str.lower().str.contains(str.lower('Wuhan'))\n",
    "Tweets['Yahoo']=Tweets['Display Name'].str.lower().str.contains(str.lower('Yahoo'))\n",
    "Tweets['Zone']=Tweets['Display Name'].str.lower().str.contains(str.lower('Zone'))\n",
    "Tweets['Zydus']=Tweets['Display Name'].str.lower().str.contains(str.lower('Zydus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276030,
     "status": "ok",
     "timestamp": 1619672044285,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "dEjgLLw75gg-",
    "outputId": "7a13e122-fddd-456d-fca3-587bdcf6ebce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7839, 181)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        USAGov\n",
       "1                                       Matthew\n",
       "2                              The Street Press\n",
       "3                        Demosthenies MAN / MAN\n",
       "4                                 NxtLevelPromo\n",
       "                         ...                   \n",
       "7834                                  C Stewart\n",
       "7835                            Exposing It All\n",
       "7836                        Alberta Prime Times\n",
       "7837    Radio TFI (Home of The Taxi Stand Hour)\n",
       "7838                             Jordan Shearer\n",
       "Name: Display Name, Length: 7839, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets['Display Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Suu_jbrE3Dre"
   },
   "outputs": [],
   "source": [
    "#User_Name = Tweets['Display Name'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfJjd-ET4-hk"
   },
   "outputs": [],
   "source": [
    "#User_Name.to_csv('User_Name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 129557,
     "status": "ok",
     "timestamp": 1619672748671,
     "user": {
      "displayName": "Vivek Kumar",
      "photoUrl": "",
      "userId": "10816717870890478108"
     },
     "user_tz": 300
    },
    "id": "nHhkEKQ_MbOM"
   },
   "outputs": [],
   "source": [
    "Tweets.to_csv('Tweets_Business_Keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUwGCAvQMk5Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sRF--DgTCFzC"
   },
   "outputs": [],
   "source": [
    "Tweets = Tweets[(Tweets['.com']==False) & (Tweets['.net']==False) &  (Tweets['24/7']==False) &  (Tweets['ABC']==False) &  (Tweets['ABS']==False) &  (Tweets['Affair']==False) \n",
    "#&  (Tweets['Africa']==False) &  (Tweets['agency']==False) &  (Tweets['Jazeera']==False) &  (Tweets['alert']==False) &  (Tweets['America']==False) &  (Tweets['Asia']==False) \n",
    "#&  (Tweets['Association']==False) &  (Tweets['AstraZeneca']==False) &  (Tweets['Australia']==False) &  (Tweets['BBC']==False) &  (Tweets['BioNTech']==False) &  (Tweets['Biotech']==False) \n",
    "#&  (Tweets['Bloomberg']==False) &  (Tweets['breaking']==False) &  (Tweets['Brief']==False) &  (Tweets['Briefly']==False) &  (Tweets['Bulletin']==False) &  (Tweets['Business']==False) \n",
    "#&  (Tweets['Buzz']==False) &  (Tweets['Canada']==False) &  (Tweets['CBS']==False) &  (Tweets['CDC']==False) &  (Tweets['Central']==False) &  (Tweets['channel']==False) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7c7Rr0Z5-zz2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_38024/480735487.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Tweets' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jLcVnChqDPz3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tweets_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hx/0dxb0wn51wx5pscstjkwf2gc000qqf/T/ipykernel_38024/1668148775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Tweets_1 = Tweets_1[(  Tweets_1['China']==False) &  (  Tweets_1['Chronicle']==False) &  (  Tweets_1['Circuit']==False) &  (  Tweets_1['Citizen']==False) &  (  Tweets_1['city']==False) &  (  Tweets_1['CNA']==False) \n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CNN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Commercial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'consulting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CoronaVac'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Council'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Covaxin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Covid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Covid-19'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CoviShield'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Current'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CVS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daily'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Desk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dialogue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Digital'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Eastern'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Economic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Empire'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EpiVacCorona'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Europe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Express'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Federation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m  \u001b[0;34m(\u001b[0m  \u001b[0mTweets_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feeds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tweets_1' is not defined"
     ]
    }
   ],
   "source": [
    "Tweets_1 = Tweets_1[(  Tweets_1['China']==False) &  (  Tweets_1['Chronicle']==False) &  (  Tweets_1['Circuit']==False) &  (  Tweets_1['Citizen']==False) &  (  Tweets_1['city']==False) &  (  Tweets_1['CNA']==False) \n",
    "&  (  Tweets_1['CNN']==False) &  (  Tweets_1['Commercial']==False) &  (  Tweets_1['consulting']==False) &  (  Tweets_1['CoronaVac']==False) &  (  Tweets_1['Council']==False) &  (  Tweets_1['county']==False) \n",
    "&  (  Tweets_1['Covaxin']==False) &  (  Tweets_1['Covid']==False) &  (  Tweets_1['Covid-19']==False) &  (  Tweets_1['CoviShield']==False) &  (  Tweets_1['Current']==False) &  (  Tweets_1['CVS']==False) \n",
    "&  (  Tweets_1['daily']==False) &  (  Tweets_1['Desk']==False) &  (  Tweets_1['Dialogue']==False) &  (  Tweets_1['Digital']==False) &  (  Tweets_1['Eastern']==False) &  (  Tweets_1['Economic']==False) \n",
    "&  (  Tweets_1['Empire']==False) &  (  Tweets_1['EpiVacCorona']==False) &  (  Tweets_1['Europe']==False) &  (  Tweets_1['Express']==False) &  (  Tweets_1['Federation']==False) &  (  Tweets_1['feeds']==False) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGCkgVq3Ecwe"
   },
   "outputs": [],
   "source": [
    "Tweets_1 =   Tweets_1[(  Tweets_1['Finder']==False) &  (  Tweets_1['First']==False) &  (  Tweets_1['Forbes']==False) &  (  Tweets_1['Fox']==False) &  (  Tweets_1['General']==False) &  (  Tweets_1['global']==False) \n",
    "&  (  Tweets_1['gov']==False) &  (  Tweets_1['group']==False) &  (  Tweets_1['Guardian']==False) &  (  Tweets_1['headline']==False) &  (  Tweets_1['Headlines']==False) &  (  Tweets_1['health']==False) \n",
    "&  (  Tweets_1['hospital']==False) &  (  Tweets_1['Hour']==False) &  (  Tweets_1['Hub']==False) &  (  Tweets_1['India']==False) &  (  Tweets_1['Insider']==False) &  (  Tweets_1['Issues']==False) \n",
    "&  (  Tweets_1['Janssen']==False) &  (  Tweets_1['Johnson & Johnson']==False) &  (  Tweets_1['J&J']==False) &  (  Tweets_1['Journal']==False) &  (  Tweets_1['Journalists']==False) &  (  Tweets_1['Kroger']==False) \n",
    "&  (  Tweets_1['Latest']==False) &  (  Tweets_1['Live']==False) &  (  Tweets_1['LLC']==False) &  (  Tweets_1['local']==False) &  (  Tweets_1['mail']==False) &  (  Tweets_1['Market']==False) &  (  Tweets_1['mass']==False) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI2ee8gzEmZj"
   },
   "outputs": [],
   "source": [
    "Tweets_1 = Tweets_1[(  Tweets_1['media']==False) &  (  Tweets_1['Medical']==False) &  (  Tweets_1['Medium']==False) &  (  Tweets_1['Messenger']==False) &  (  Tweets_1['Moderna']==False) &  (  Tweets_1['Month']==False) \n",
    "&  (  Tweets_1['Morning']==False) &  (  Tweets_1['nation']==False) &  (  Tweets_1['National']==False) &  (  Tweets_1['NBC']==False) &  (  Tweets_1['network']==False) &  (  Tweets_1['New York']==False) \n",
    "&  (  Tweets_1['news']==False) &  (  Tweets_1['Newspaper']==False) &  (  Tweets_1['Novavax']==False) &  (  Tweets_1['Now']==False) &  (  Tweets_1['online']==False) &  (  Tweets_1['Org']==False) \n",
    "&  (  Tweets_1['organization']==False) &  (  Tweets_1['Pandemic']==False) &  (  Tweets_1['Pfizer']==False) &  (  Tweets_1['Pharmacy']==False) &  (  Tweets_1['Philippines']==False) &  (  Tweets_1['Podcast']==False) \n",
    "&  (  Tweets_1['Policy']==False) &  (  Tweets_1['Political']==False) &  (  Tweets_1['Popular']==False) &  (  Tweets_1['Post']==False) &  (  Tweets_1['press']==False) &  (  Tweets_1['Progress']==False) \n",
    "&  (  Tweets_1['Project']==False) &  (  Tweets_1['Public']==False) &  (  Tweets_1['Radio']==False) &  (  Tweets_1['Reporter']==False) &  (  Tweets_1['Republic']==False) &  (  Tweets_1['Reuters']==False) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Flk4gegcEz6m"
   },
   "outputs": [],
   "source": [
    "Tweets_1 = Tweets_1[(  Tweets_1['Science']==False) &  (  Tweets_1['Sinopharm']==False) &  (  Tweets_1['Sinovac']==False) &  (  Tweets_1['Sky']==False) &  (  Tweets_1['Society']==False) &  (  Tweets_1['Sputnik']==False) \n",
    "&  (  Tweets_1['Square']==False) &  (  Tweets_1['state']==False) &  (  Tweets_1['Stigma']==False) &  (  Tweets_1['Street']==False) &  (  Tweets_1['Studio']==False) &  (  Tweets_1['Talk']==False) \n",
    "&  (  Tweets_1['team']==False) &  (  Tweets_1['Tech']==False) &  (  Tweets_1['Technology']==False) &  (  Tweets_1['Telegram']==False) &  (  Tweets_1['Telegraph']==False) &  (  Tweets_1['times']==False) \n",
    "&  (  Tweets_1['today']==False) &  (  Tweets_1['TOI']==False) &  (  Tweets_1['Top']==False) &  (  Tweets_1['Top10']==False) &  (  Tweets_1['trend']==False) &  (  Tweets_1['Tribune']==False) &  (  Tweets_1['TV']==False) \n",
    "&  (  Tweets_1['Union']==False) &  (  Tweets_1['update']==False) &  (  Tweets_1['USA']==False) &  (  Tweets_1['vaccine']==False) &  (  Tweets_1['Viral']==False) &  (  Tweets_1['Voice']==False) \n",
    "&  (  Tweets_1['Walgreens']==False) &  (  Tweets_1['Watch']==False) &  (  Tweets_1['Week1']==False) &  (  Tweets_1['Western']==False) &  (  Tweets_1['WHO']==False) &  (  Tweets_1['Wire']==False) \n",
    "&  (  Tweets_1['world']==False) &  (  Tweets_1['Wuhan']==False) &  (  Tweets_1['Yahoo']==False) &  (  Tweets_1['Zone']==False) & (  Tweets_1['Zydus']==False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTJzG5Y0E9SK"
   },
   "outputs": [],
   "source": [
    "Tweets_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dHysaJco650"
   },
   "outputs": [],
   "source": [
    "#Tweets_1.to_csv('Personal_Tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkVyerj3hGGm"
   },
   "outputs": [],
   "source": [
    "#Tweets_User_Name = pd.DataFrame(Tweets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLgpoJjihSAg"
   },
   "outputs": [],
   "source": [
    "#Tweets_User_Name.to_csv('Tweets_User_Name.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPBefIpMcP+9XwrNCw8rkeC",
   "collapsed_sections": [],
   "mount_file_id": "1sNI7909WFAh2NHa1qvZagLZnxqa2gXVi",
   "name": "Individuals vs Businesses(Part1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "twitter-covid-test",
   "language": "python",
   "name": "twitter-covid-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
